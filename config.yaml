# Configuration for GH200 Training

data:
  urls:
    - "http://images.cocodataset.org/zips/train2017.zip"
    - "http://images.cocodataset.org/zips/val2017.zip"
    - "http://images.cocodataset.org/zips/test2017.zip"

  raw_dir: "data/raw"
  extracted_dir: "data/coco"
  processed_dir: "data/shards"

  samples_per_shard: 10000
  processing_workers: 32  # GH200 has 72 ARM cores
  image_size: 256
  rotations: [0, 90, 180, 270]

model:
  name: "apple/mobilevitv2-1.0-imagenet1k-256"
  num_classes: 4
  normalize:
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]

training:
  output_dir: "checkpoints"
  logs_dir: "logs"

  batch_size: 1024  # GH200 has 96GB HBM3
  epochs: 10
  learning_rate: 1.0e-3
  weight_decay: 1.0e-4

  optimizer: "adamw"
  scheduler: "cosine"
  warmup_epochs: 1

  patience: 3
  min_delta: 0.001

  num_workers: 32
  pin_memory: true
  mixed_precision: true
  gradient_accumulation: 1
  compile_model: true

  save_every_n_epochs: 1
  keep_n_checkpoints: 3

export:
  coreml:
    enabled: true
    target_ios: 17
    fp16: true

  onnx:
    enabled: false
    opset_version: 17

logging:
  level: "INFO"
  console: true
  file: true